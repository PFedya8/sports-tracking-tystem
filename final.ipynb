{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import gc\n",
    "from typing import List, Tuple, Optional\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO  \n",
    "import torch\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_data(images_dir, labels_dir, train_images_dir, train_labels_dir, val_images_dir, val_labels_dir, split_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Разделяет данные на обучающую и валидационную выборки.\n",
    "    \n",
    "    Args:\n",
    "        images_dir (Path): Путь к корневой директории с изображениями (processed_images/train/).\n",
    "        labels_dir (Path): Путь к корневой директории с аннотациями YOLO (processed_labels/train/).\n",
    "        train_images_dir (Path): Путь к директории для обучающих изображений.\n",
    "        train_labels_dir (Path): Путь к директории для обучающих аннотаций.\n",
    "        val_images_dir (Path): Путь к директории для валидационных изображений.\n",
    "        val_labels_dir (Path): Путь к директории для валидационных аннотаций.\n",
    "        split_ratio (float, optional): Доля данных для обучения.\n",
    "    \"\"\"\n",
    "    # Собираем все изображения и аннотации\n",
    "    image_files = list(images_dir.glob('*.jpg'))\n",
    "    label_files = list(labels_dir.glob('*.txt'))\n",
    "    \n",
    "    print(f\"Найдено {len(image_files)} изображений и {len(label_files)} аннотаций.\")\n",
    "    \n",
    "    # Создаём словари для сопоставления изображений и аннотаций по имени файла\n",
    "    image_dict = {img.stem: img for img in image_files}\n",
    "    label_dict = {lbl.stem: lbl for lbl in label_files}\n",
    "    \n",
    "    # Нахождение общих ключей (имена файлов без расширений)\n",
    "    common_keys = set(image_dict.keys()).intersection(set(label_dict.keys()))\n",
    "    \n",
    "    print(f\"Найдено {len(common_keys)} общих пар изображений и аннотаций.\")\n",
    "    \n",
    "    if len(common_keys) == 0:\n",
    "        print(\"Нет общих пар изображений и аннотаций. Проверьте, правильно ли выполнена конвертация аннотаций.\")\n",
    "        return\n",
    "    \n",
    "    # Создаём списки общих изображений и аннотаций\n",
    "    common_images = [image_dict[k] for k in common_keys]\n",
    "    common_labels = [label_dict[k] for k in common_keys]\n",
    "    \n",
    "    # Перемешиваем данные\n",
    "    combined = list(zip(common_images, common_labels))\n",
    "    random.shuffle(combined)\n",
    "    common_images[:], common_labels[:] = zip(*combined)\n",
    "    \n",
    "    # Определяем индекс разделения\n",
    "    split_idx = int(len(common_images) * split_ratio)\n",
    "    train_images = common_images[:split_idx]\n",
    "    train_labels = common_labels[:split_idx]\n",
    "    val_images = common_images[split_idx:]\n",
    "    val_labels = common_labels[split_idx:]\n",
    "    \n",
    "    print(f\"Копирование {len(train_images)} изображений и аннотаций в обучающую выборку.\")\n",
    "    print(f\"Копирование {len(val_images)} изображений и аннотаций в валидационную выборку.\")\n",
    "    \n",
    "    # Копируем обучающие данные\n",
    "    for img, lbl in zip(train_images, train_labels):\n",
    "        shutil.copy(img, train_images_dir / img.name)\n",
    "        shutil.copy(lbl, train_labels_dir / lbl.name)\n",
    "    \n",
    "    # Копируем валидационные данные\n",
    "    for img, lbl in zip(val_images, val_labels):\n",
    "        shutil.copy(img, val_images_dir / img.name)\n",
    "        shutil.copy(lbl, val_labels_dir / lbl.name)\n",
    "    \n",
    "    print(\"Разделение данных завершено.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Metrics:\n",
    "    @staticmethod\n",
    "    def position_error(label_gt: np.ndarray, label_pr: np.ndarray, step=8, alpha=1.5, e1=5, e2=5) -> float:\n",
    "        # Коды gt:\n",
    "        # 0 - мяч не в кадре\n",
    "        # 1 - мяч легко идентифицируем\n",
    "        # 2 - мяч в кадре, но не легко идентифицируем\n",
    "        # 3 - мяч скрыт\n",
    "        if label_gt[0] != 0 and label_pr[0] == 0:\n",
    "            return e1\n",
    "        if label_gt[0] == 0 and label_pr[0] != 0:\n",
    "            return e2\n",
    "        dist = math.sqrt((label_gt[1] - label_pr[1]) ** 2 + (label_gt[2] - label_pr[2]) ** 2)\n",
    "        pe = math.floor(dist / step) ** alpha\n",
    "        pe = min(pe, 5)\n",
    "        return pe\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate_predictions(labels_gt: np.ndarray, labels_pr: np.ndarray) -> Tuple[List[float], float]:\n",
    "        pe = [Metrics.position_error(labels_gt[i], labels_pr[i]) for i in range(len(labels_gt))]\n",
    "        SIBATRACC_vals = []\n",
    "        for i in range(len(pe)):\n",
    "            cumulative_pe = sum(pe[:i + 1])\n",
    "            SIBATRACC_vals.append(1 - cumulative_pe / ((i + 1) * 5))\n",
    "        SIBATRACC_total = 1 - sum(pe) / (len(labels_gt) * 5) if len(labels_gt) > 0 else 0\n",
    "        return SIBATRACC_vals, SIBATRACC_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "import gdown\n",
    "\n",
    "def get_game_clip_pairs(data_path: Path, games: List[int]) -> List[tuple]:\n",
    "    image_dir = data_path / \"images\" / \"test\"\n",
    "    clip_names = set()\n",
    "    for image_file in image_dir.glob(\"*.jpg\"):\n",
    "        parts = image_file.name.split('_')\n",
    "        clip_name = '_'.join(parts[:-1])\n",
    "        clip_names.add(clip_name)\n",
    "\n",
    "    game_clip_pairs = []\n",
    "    for clip_name in sorted(clip_names):\n",
    "        g_part = clip_name.split('_')[0]  \n",
    "        g_num = int(g_part.replace('game', ''))\n",
    "        if g_num in games:\n",
    "            game_clip_pairs.append((g_num, clip_name))\n",
    "            \n",
    "    return game_clip_pairs\n",
    "\n",
    "\n",
    "class CustomTrackingModel:\n",
    "    def __init__(self, batch_size: int, stack_size: int, model_path: Path, data_path: Path, output_path: Path):\n",
    "        self.batch_size = batch_size\n",
    "        self.stack_size = stack_size\n",
    "        self.model_path = model_path\n",
    "        self.data_path = data_path\n",
    "        self.output_path = output_path\n",
    "        self.model = None  # Будет загружена в методе load()\n",
    "\n",
    "    def load(self, path=\"best.pt\", load_from_cloud=True):\n",
    "        # LBL5\n",
    "        print(\"Загрузка модели YOLOv11...\")\n",
    "        if load_from_cloud:\n",
    "            url = f\"https://drive.google.com/uc?id=1Wegd5CSWgk6iKoyDNmex6gNwhUmkhSQI\"\n",
    "            print(f\"Loading model from {url}\")\n",
    "            gdown.download(url, path, quiet=False)\n",
    "            print(f\"Loading model from {path}\")\n",
    "            self.model = YOLO(str(path), task='detect')\n",
    "\n",
    "        else:\n",
    "            self.model = YOLO(str(self.model_path))\n",
    "        print(\"Модель YOLOv11 успешно загружена.\")\n",
    "\n",
    "    def load_images(self, clip_name: str) -> np.ndarray:\n",
    "        image_dir = self.data_path / \"images\" / \"test\"\n",
    "        images = []\n",
    "        for image_file in sorted(image_dir.glob(f\"{clip_name}*.jpg\")):\n",
    "            img = Image.open(image_file).convert(\"RGB\")\n",
    "            images.append(np.array(img))\n",
    "        return np.array(images)\n",
    "\n",
    "    def load_labels(self, clip_name: str) -> np.ndarray:\n",
    "        label_dir = self.data_path / \"labels\" / \"test\"\n",
    "        labels = []\n",
    "        image_width = 1280\n",
    "        image_height = 720\n",
    "\n",
    "        for label_file in sorted(label_dir.glob(f\"{clip_name}*.txt\")):\n",
    "            with open(label_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                if len(lines) == 0:\n",
    "                    labels.append([0.0, 0.0, 0.0])\n",
    "                else:\n",
    "                    class_id, x_center, y_center, width, height = map(float, lines[0].split())\n",
    "                    x_center_abs = x_center * image_width\n",
    "                    y_center_abs = y_center * image_height\n",
    "                    labels.append([class_id, x_center_abs, y_center_abs])\n",
    "        \n",
    "        return np.array(labels)\n",
    "    \n",
    "    def convert_labels_to_yolo(self, game, clip, image_dir, label_csv, output_images_dir, output_labels_dir, image_width=1280, image_height=720):\n",
    "        #LBL4\n",
    "        \"\"\"\n",
    "        Конвертирует аннотации из labels.csv в формат YOLO с уникальными именами файлов.\n",
    "        Копирует изображения в единую директорию с уникальными именами.\n",
    "        Записывает все аннотации для одного изображения в один .txt файл.\n",
    "        \n",
    "        Args:\n",
    "            game (str): Название игры (например, 'game1').\n",
    "            clip (str): Название клипа (например, 'clip1').\n",
    "            image_dir (Path): Путь к директории с изображениями.\n",
    "            label_csv (Path): Путь к файлу labels.csv.\n",
    "            output_images_dir (Path): Путь к директории для сохранения изображений с уникальными именами.\n",
    "            output_labels_dir (Path): Путь к директории для сохранения YOLO-аннотаций.\n",
    "            image_width (int): Ширина изображений.\n",
    "            image_height (int): Высота изображений.\n",
    "        \"\"\"\n",
    "        output_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        output_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        if not label_csv.exists():\n",
    "            print(f\"Файл {label_csv} не найден. Пропуск...\")\n",
    "            return\n",
    "        \n",
    "        df = pd.read_csv(label_csv)\n",
    "        \n",
    "        grouped = df.groupby('file name')\n",
    "        \n",
    "        for filename, group in grouped:\n",
    "            visibility = group['visibility'].iloc[0] \n",
    "            if visibility == 0:\n",
    "\n",
    "                unique_stem = f\"{game}_{clip}_{Path(filename).stem}\"\n",
    "                label_path = output_labels_dir / f\"{unique_stem}.txt\"\n",
    "                label_path.touch(exist_ok=True)\n",
    "                \n",
    "                image_path = image_dir / filename\n",
    "                unique_image_name = f\"{unique_stem}.jpg\"\n",
    "                new_image_path = output_images_dir / unique_image_name\n",
    "                if not new_image_path.exists():\n",
    "                    shutil.copy(image_path, new_image_path)\n",
    "                continue\n",
    "            \n",
    "            yolo_annotations = []\n",
    "            \n",
    "            for _, row in group.iterrows():\n",
    "                x = row['x-coordinate']\n",
    "                y = row['y-coordinate']\n",
    "                status = row['status']\n",
    "                visibility = row['visibility']\n",
    "\n",
    "                if pd.isna(x) or pd.isna(y):\n",
    "                    continue\n",
    "\n",
    "                x_center = float(x) / image_width\n",
    "                y_center = float(y) / image_height\n",
    "\n",
    "                width = 0.05\n",
    "                height = 0.05\n",
    "\n",
    "                \n",
    "                class_id = int(visibility)\n",
    "\n",
    "                yolo_annotation = f\"{class_id} {x_center} {y_center} {width} {height}\"\n",
    "                yolo_annotations.append(yolo_annotation)\n",
    "            \n",
    "            if not yolo_annotations:\n",
    "                unique_stem = f\"{game}_{clip}_{Path(filename).stem}\"\n",
    "                label_path = output_labels_dir / f\"{unique_stem}.txt\"\n",
    "                label_path.touch(exist_ok=True)\n",
    "            else:\n",
    "                unique_stem = f\"{game}_{clip}_{Path(filename).stem}\"\n",
    "                \n",
    "                label_path = output_labels_dir / f\"{unique_stem}.txt\"\n",
    "                with open(label_path, 'w') as f:\n",
    "                    f.write('\\n'.join(yolo_annotations) + '\\n')\n",
    "            \n",
    "            image_path = image_dir / filename\n",
    "            unique_image_name = f\"{unique_stem}.jpg\"\n",
    "            new_image_path = output_images_dir / unique_image_name\n",
    "            if not new_image_path.exists():\n",
    "                shutil.copy(image_path, new_image_path)\n",
    "\n",
    "    def predict_on_batch(self, batch: np.ndarray) -> List[dict]:\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Модель не загружена. Вызовите метод load() перед предсказанием.\")\n",
    "        image_list = [Image.fromarray(img) for img in batch.astype(np.uint8)]\n",
    "        results = self.model(image_list, verbose=False)\n",
    "        return results\n",
    "\n",
    "    def get_labels_from_prediction(self, predictions: List[Optional[dict]], upscale_coords: bool, original_size: Tuple[int, int]) -> np.ndarray:\n",
    "        coords = np.zeros((len(predictions), 7), dtype=np.float32) \n",
    "        original_width, original_height = original_size\n",
    "        \n",
    "        for i, frame_preds in enumerate(predictions):\n",
    "            if frame_preds is None or not frame_preds.boxes:\n",
    "                coords[i] = [0, 0, 0, 0, 0, 0, 0]\n",
    "                continue\n",
    "            ball_pred = max(frame_preds.boxes, key=lambda box: box.conf)\n",
    "            class_id = int(ball_pred.cls)\n",
    "            x1 = float(ball_pred.xyxy[0][0])\n",
    "            y1 = float(ball_pred.xyxy[0][1])\n",
    "            x2 = float(ball_pred.xyxy[0][2])\n",
    "            y2 = float(ball_pred.xyxy[0][3])\n",
    "            x_center = (x1 + x2) / 2\n",
    "            y_center = (y1 + y2) / 2\n",
    "            if upscale_coords:\n",
    "                scale_x = original_width / frame_preds.orig_shape[1]\n",
    "                scale_y = original_height / frame_preds.orig_shape[0]\n",
    "                x_center *= scale_x\n",
    "                y_center *= scale_y\n",
    "                x1 *= scale_x\n",
    "                y1 *= scale_y\n",
    "                x2 *= scale_x\n",
    "                y2 *= scale_y\n",
    "            coords[i] = [class_id, x_center, y_center, x1, y1, x2, y2]\n",
    "        \n",
    "        return coords\n",
    "\n",
    "    def evaluate_predictions(self, ground_truth: np.ndarray, predictions: np.ndarray) -> float:\n",
    "        SIBATRACC_per_frame, SIBATRACC_total = Metrics.evaluate_predictions(ground_truth, predictions)\n",
    "        return SIBATRACC_total\n",
    "\n",
    "    def test(self, data_path: Path, games: List[int], do_visualization=False, test_name='test', yolo_format=False) -> float:\n",
    "        if not yolo_format:\n",
    "            test_games = games\n",
    "            test_dir = data_path / test_name\n",
    "\n",
    "            output_images_dir = Path('processed_images/test/')\n",
    "            output_labels_dir = Path('processed_labels/test/')\n",
    "\n",
    "            for game in test_games:\n",
    "                game_dir = test_dir / f'game{game}'\n",
    "                if not game_dir.exists():\n",
    "                    print(f\"Директория {game_dir} не найдена. Пропуск...\")\n",
    "                    continue\n",
    "                for clip in game_dir.iterdir():\n",
    "                    if clip.is_dir():\n",
    "                        image_dir = clip\n",
    "                        label_csv = clip / 'labels.csv'\n",
    "                        if label_csv.exists():\n",
    "                            self.convert_labels_to_yolo(\n",
    "                                game=f'game{game}',\n",
    "                                clip=clip.name,\n",
    "                                image_dir=image_dir,\n",
    "                                label_csv=label_csv,\n",
    "                                output_images_dir=output_images_dir,\n",
    "                                output_labels_dir=output_labels_dir,\n",
    "                                image_width=1280,\n",
    "                                image_height=720\n",
    "                            )\n",
    "                        else:\n",
    "                            print(f\"Файл {label_csv} не найден в {clip}. Пропуск...\")\n",
    "\n",
    "            test_images_dir = Path('dataset/images/test/')\n",
    "            test_labels_dir = Path('dataset/labels/test/')\n",
    "            test_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "            test_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            split_data(\n",
    "                images_dir=output_images_dir,\n",
    "                labels_dir=output_labels_dir,\n",
    "                train_images_dir=test_images_dir,\n",
    "                train_labels_dir=test_labels_dir,\n",
    "                val_images_dir=None,\n",
    "                val_labels_dir=None,\n",
    "                split_ratio=1.0\n",
    "            )\n",
    "\n",
    "            \n",
    "        game_clip_pairs = get_game_clip_pairs(self.data_path, games)\n",
    "        SIBATRACC_vals = []\n",
    "        for game, clip_name in game_clip_pairs:\n",
    "            data = self.load_images(clip_name)\n",
    "            labels_gt = self.load_labels(clip_name)\n",
    "\n",
    "            predictions = self.predict_on_batch(data)\n",
    "            predicted_labels = self.get_labels_from_prediction(predictions, upscale_coords=True, original_size=(1280, 720))\n",
    "\n",
    "            SIBATRACC_per_frame, SIBATRACC_total = Metrics.evaluate_predictions(labels_gt, predicted_labels)\n",
    "            SIBATRACC_vals.append(SIBATRACC_total)\n",
    "\n",
    "            if do_visualization:\n",
    "                self.visualize_predictions(data, predicted_labels, clip_name)\n",
    "\n",
    "            del data, labels_gt, predicted_labels, predictions\n",
    "            gc.collect()\n",
    "\n",
    "        SIBATRACC_final = sum(SIBATRACC_vals) / len(SIBATRACC_vals) if SIBATRACC_vals else 0\n",
    "        return SIBATRACC_final\n",
    "\n",
    "    def visualize_predictions(self, images: np.ndarray, predicted_labels: np.ndarray, clip_name: str):\n",
    "        visualize_path = self.output_path / \"visualizations\"\n",
    "        visualize_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for i, img in enumerate(images):\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            \n",
    "            class_id, x_center, y_center, x1, y1, x2, y2 = predicted_labels[i]\n",
    "\n",
    "            if class_id != 0:\n",
    "                rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor='red', linewidth=2)\n",
    "                plt.gca().add_patch(rect)\n",
    "                plt.scatter(x_center, y_center, c='blue', s=20, marker='x')\n",
    "                plt.text(x1, y1 - 5, f'Class: {class_id}', color='yellow', fontsize=12, backgroundcolor='black')\n",
    "            \n",
    "            plt.title(f'{clip_name} Frame {i}')\n",
    "            save_path = visualize_path / f\"{clip_name}_frame_{i}.jpg\"\n",
    "            plt.savefig(save_path, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "    def train_model(self, data_config: Path, epochs: int = 50, imgsz: int = 640, load_existing: bool = True, yolo_format: bool = False):\n",
    "        # LBL1, LBL2, LBL3, LBL6, LBL13, LBL7\n",
    "        if not yolo_format:\n",
    "            train_games = [1, 2, 3, 4, 5, 6]  # Список игр для обучения\n",
    "            train_dir = Path('tennis/train/')  # Путь к тренировочным данным\n",
    "            yolo_labels_dir = Path('yolo_labels/train/')  # Путь для сохранения YOLO-аннотаций\n",
    "\n",
    "            # Путь к целевым директориям с уникальными именами\n",
    "            output_images_dir = Path('processed_images/train/')\n",
    "            output_labels_dir = Path('processed_labels/train/')\n",
    "\n",
    "            for game in train_games:\n",
    "                game_dir = train_dir / f'game{game}'\n",
    "                if not game_dir.exists():\n",
    "                    print(f\"Директория {game_dir} не найдена. Пропуск...\")\n",
    "                    continue\n",
    "                for clip in game_dir.iterdir():\n",
    "                    if clip.is_dir():\n",
    "                        image_dir = clip\n",
    "                        label_csv = clip / 'labels.csv'\n",
    "                        if label_csv.exists():\n",
    "                            self.convert_labels_to_yolo(\n",
    "                                game=f'game{game}',\n",
    "                                clip=clip.name,\n",
    "                                image_dir=image_dir,\n",
    "                                label_csv=label_csv,\n",
    "                                output_images_dir=output_images_dir,\n",
    "                                output_labels_dir=output_labels_dir,\n",
    "                                image_width=1280,\n",
    "                                image_height=720\n",
    "                            )\n",
    "                        else:\n",
    "                            print(f\"Файл {label_csv} не найден в {clip}. Пропуск...\")\n",
    "            train_images_dir = Path('dataset/images/train/')\n",
    "            train_labels_dir = Path('dataset/labels/train/')\n",
    "            val_images_dir = Path('dataset/images/val/')\n",
    "            val_labels_dir = Path('dataset/labels/val/')\n",
    "\n",
    "            train_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "            train_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "            val_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "            val_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            processed_images_dir = Path('processed_images/train/')\n",
    "            processed_labels_dir = Path('processed_labels/train/')\n",
    "\n",
    "            split_data(\n",
    "                images_dir=processed_images_dir,\n",
    "                labels_dir=processed_labels_dir,\n",
    "                train_images_dir=train_images_dir,\n",
    "                train_labels_dir=train_labels_dir,\n",
    "                val_images_dir=val_images_dir,\n",
    "                val_labels_dir=val_labels_dir,\n",
    "                split_ratio=0.8\n",
    "            )\n",
    "        if self.model is None:\n",
    "            if self.model_path.exists() and load_existing:\n",
    "                self.model = YOLO(str(self.model_path))\n",
    "            else:\n",
    "                self.model = YOLO('yolo11l.pt')  \n",
    "\n",
    "        self.model.train(\n",
    "            data=str(data_config),\n",
    "            epochs=epochs,\n",
    "            batch=self.batch_size,\n",
    "            imgsz=imgsz,\n",
    "            workers=32,\n",
    "            device='0'\n",
    "        )\n",
    "\n",
    "    def predict_with_tracking(self, clip_name: str, image_dir: Path) -> List[dict]:\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Модель не загружена. Вызовите метод load() перед предсказанием.\")\n",
    "\n",
    "        results = self.model.track(source=str(image_dir), conf=0.5, save=False, verbose=False, iou=0.5)\n",
    "        all_predictions = []\n",
    "        for res in results:\n",
    "            frame_data = []\n",
    "            for box in res.boxes:\n",
    "                cls = int(box.cls)\n",
    "                conf = float(box.conf)\n",
    "                x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "                track_id = int(box.id) if box.id is not None else -1\n",
    "                x_center = (x1 + x2) / 2.0\n",
    "                y_center = (y1 + y2) / 2.0\n",
    "                frame_data.append({\n",
    "                    'class_id': cls,\n",
    "                    'conf': conf,\n",
    "                    'track_id': track_id,\n",
    "                    'x_center': x_center,\n",
    "                    'y_center': y_center,\n",
    "                    'x1': x1,\n",
    "                    'y1': y1,\n",
    "                    'x2': x2,\n",
    "                    'y2': y2\n",
    "                })\n",
    "            all_predictions.append(frame_data)\n",
    "\n",
    "        return all_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.51 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.47 🚀 Python-3.11.5 torch-2.5.1+cu124 CUDA:0 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:1 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:3 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:4 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:5 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:6 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:7 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11l.pt, data=dataset.yaml, epochs=50, time=None, patience=100, batch=70, imgsz=640, save=True, save_period=-1, cache=False, device=[0, 1, 3, 4, 5, 6, 7], workers=32, project=None, name=train10, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734640904.815290 3999282 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734640904.820624 3999282 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 23        [16, 19, 22]  1   1414108  ultralytics.nn.modules.head.Detect           [4, [256, 512, 512]]          \n",
      "YOLO11l summary: 631 layers, 25,313,564 parameters, 25,313,548 gradients, 87.3 GFLOPs\n",
      "\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/notebooks/sports-tracking-tystem/.venv/bin/python -m torch.distributed.run --nproc_per_node 7 --master_port 55979 /root/.config/Ultralytics/DDP/_temp_ynql0j5c140609300772880.py\n",
      "Ultralytics 8.3.47 🚀 Python-3.11.5 torch-2.5.1+cu124 CUDA:0 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:1 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:3 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:4 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:5 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:6 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:7 (NVIDIA A100-SXM4-80GB, 81158MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734640914.896321 3999908 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734640914.901641 3999908 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train10', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /opt/notebooks/sports-tracking-tystem/dataset/labels/train... 11903 images, 599 backgrounds, 0 corrupt: 100%|██████████| 11903/11903 [00:08<00:00, 1330.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /opt/notebooks/sports-tracking-tystem/dataset/labels/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /opt/notebooks/sports-tracking-tystem/dataset/labels/val... 7982 images, 402 backgrounds, 0 corrupt: 100%|██████████| 7982/7982 [00:05<00:00, 1495.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /opt/notebooks/sports-tracking-tystem/dataset/labels/val.cache\n",
      "Plotting labels to runs/detect/train10/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.000546875), 173 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 126 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train10\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      7.27G      1.903      3.521      1.155          1        640: 100%|██████████| 171/171 [00:48<00:00,  3.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:33<00:00, 12.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.711      0.354      0.419      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      7.29G      1.294      1.147     0.9191          0        640: 100%|██████████| 171/171 [00:47<00:00,  3.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:33<00:00, 11.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.879      0.255      0.285      0.188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      7.35G      1.215      1.088     0.9017          1        640: 100%|██████████| 171/171 [00:46<00:00,  3.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.706      0.343      0.362      0.224\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      7.31G      1.136     0.9801     0.8895          2        640: 100%|██████████| 171/171 [00:46<00:00,  3.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.665      0.339      0.336      0.243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      7.29G      1.032     0.8959     0.8724          4        640: 100%|██████████| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.631      0.366      0.432      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      7.29G     0.9787     0.8666     0.8584          1        640: 100%|██████████| 171/171 [00:46<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.554      0.501      0.479      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      7.28G     0.9533     0.8461     0.8493          0        640: 100%|██████████| 171/171 [00:46<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.481      0.508      0.471      0.339\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      7.28G     0.9216     0.7951     0.8447          1        640: 100%|██████████| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.552      0.512      0.476      0.354\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      7.28G     0.9077     0.7589     0.8439          1        640: 100%|██████████| 171/171 [00:46<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.567       0.54      0.492      0.353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      7.28G     0.8943     0.7603     0.8407          1        640: 100%|██████████| 171/171 [00:46<00:00,  3.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.565      0.529      0.512      0.376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      7.29G     0.8767     0.7146     0.8379          1        640: 100%|██████████| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.566      0.572      0.518      0.384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      7.28G     0.8663     0.7207     0.8346          0        640: 100%|██████████| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.568      0.558      0.529      0.403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      7.28G     0.8566      0.733     0.8368          1        640: 100%|██████████| 171/171 [00:46<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.597      0.557      0.564      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      7.29G     0.8621     0.7574     0.8381          1        640: 100%|██████████| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.669      0.504      0.541      0.415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      7.28G     0.8394     0.6983     0.8329          2        640: 100%|██████████| 171/171 [00:46<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.601      0.587      0.565      0.431\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      7.28G      0.855     0.7082     0.8342          4        640: 100%|██████████| 171/171 [00:46<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580       0.63      0.608      0.581      0.436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      7.28G     0.8241     0.6854     0.8309          0        640: 100%|██████████| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.629      0.632      0.595      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      7.28G     0.8252     0.6579     0.8328          2        640: 100%|██████████| 171/171 [00:46<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.624      0.618      0.601      0.457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      7.28G     0.8149     0.6152     0.8308          4        640: 100%|██████████| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.658      0.587      0.605      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      7.28G      0.803     0.6338      0.828          2        640: 100%|██████████| 171/171 [00:46<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.601      0.636      0.585      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      7.28G     0.7851     0.6118     0.8205          1        640: 100%|██████████| 171/171 [00:46<00:00,  3.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.672      0.631      0.619      0.472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      7.28G     0.7866     0.5894     0.8243          2        640: 100%|██████████| 171/171 [00:46<00:00,  3.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.683      0.625      0.633      0.483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      7.28G     0.7744     0.5533     0.8247          1        640: 100%|██████████| 171/171 [00:46<00:00,  3.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.637      0.623      0.634      0.489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      7.28G     0.7607     0.5766      0.818          1        640: 100%|██████████| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.632      0.653      0.646      0.486\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      7.28G     0.7399     0.5907     0.8173          2        640: 100%|██████████| 171/171 [00:46<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.678      0.646      0.648      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      7.28G      0.722     0.5677     0.8141          1        640: 100%|██████████| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.675      0.669      0.659      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      7.28G     0.7415     0.5444     0.8212          1        640: 100%|██████████| 171/171 [00:46<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580       0.64      0.682      0.647      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      7.28G     0.7215     0.5552     0.8149          3        640: 100%|██████████| 171/171 [00:46<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:31<00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.713      0.675       0.69      0.538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/171 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      7.28G      0.705     0.5276     0.8117          2        640: 100%|██████████| 171/171 [00:46<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:31<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.653      0.755      0.695      0.541\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      7.28G     0.7083     0.5047     0.8074          2        640: 100%|██████████| 171/171 [00:46<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580       0.68      0.699      0.693      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      7.28G     0.7101      0.516     0.8152          2        640: 100%|██████████| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:31<00:00, 12.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.694       0.68      0.697      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      7.28G     0.7163      0.519     0.8189          2        640: 100%|██████████| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:31<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.753      0.688      0.735      0.576\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      7.28G     0.7019     0.5146     0.8127          2        640: 100%|██████████| 171/171 [00:46<00:00,  3.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:31<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.705      0.741       0.73      0.579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      7.28G     0.6908        0.5     0.8145          2        640: 100%|██████████| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.682      0.763      0.743      0.584\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      7.28G     0.6897     0.4883     0.8018          0        640: 100%|██████████| 171/171 [00:47<00:00,  3.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:31<00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.726      0.782      0.776      0.602\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      7.28G     0.6877     0.4837     0.8078          2        640: 100%|██████████| 171/171 [00:46<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:31<00:00, 12.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.732      0.756      0.759      0.595\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      7.28G     0.6724     0.4634     0.8045          3        640: 100%|██████████| 171/171 [00:45<00:00,  3.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.795      0.731       0.78      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      7.28G     0.6663     0.4739     0.8095          2        640: 100%|██████████| 171/171 [00:46<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:32<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.787       0.74       0.78      0.613\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      7.28G     0.6695     0.4729     0.8082          2        640: 100%|██████████| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:31<00:00, 12.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.749      0.758      0.791      0.619\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      7.28G     0.6557     0.4586     0.8107          2        640: 100%|██████████| 171/171 [00:46<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:31<00:00, 12.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.747      0.765      0.793      0.621\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      7.28G      0.628     0.4141     0.8037          1        640: 100%|██████████| 171/171 [00:47<00:00,  3.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:31<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.714      0.758      0.772      0.612\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      7.28G     0.6236     0.4003     0.8073          1        640: 100%|██████████| 171/171 [00:46<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:31<00:00, 12.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.783      0.718      0.783      0.624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      7.28G     0.6257     0.4192     0.8133          1        640: 100%|██████████| 171/171 [00:47<00:00,  3.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:31<00:00, 12.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.756      0.779      0.811      0.651\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      7.28G     0.6122     0.3806     0.8022          1        640: 100%|██████████| 171/171 [00:47<00:00,  3.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:31<00:00, 12.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.791      0.757       0.81      0.652\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      7.28G     0.6222     0.4173     0.8037          1        640: 100%|██████████| 171/171 [00:47<00:00,  3.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:31<00:00, 12.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.816      0.779      0.813      0.652\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      7.28G     0.5984     0.3905     0.8007          1        640: 100%|██████████| 171/171 [00:47<00:00,  3.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:31<00:00, 12.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.819      0.782       0.82      0.658\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      7.28G     0.6078     0.3594      0.798          1        640: 100%|██████████| 171/171 [00:47<00:00,  3.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:31<00:00, 12.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.859      0.762      0.828      0.658\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      7.28G     0.6012     0.3477     0.8038          1        640: 100%|██████████| 171/171 [00:47<00:00,  3.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:31<00:00, 12.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.867      0.752      0.835      0.667\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      7.28G     0.5936     0.3474     0.8013          1        640: 100%|██████████| 171/171 [00:46<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:31<00:00, 12.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.834      0.768      0.843      0.678\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      7.28G     0.5944      0.347     0.8041          1        640: 100%|██████████| 171/171 [00:47<00:00,  3.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:31<00:00, 12.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.826      0.791       0.85      0.678\n",
      "\n",
      "50 epochs completed in 1.117 hours.\n",
      "Optimizer stripped from runs/detect/train10/weights/last.pt, 51.2MB\n",
      "Optimizer stripped from runs/detect/train10/weights/best.pt, 51.2MB\n",
      "\n",
      "Validating runs/detect/train10/weights/best.pt...\n",
      "Ultralytics 8.3.47 🚀 Python-3.11.5 torch-2.5.1+cu124 CUDA:0 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:1 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:3 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:4 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:5 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:6 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:7 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "YOLO11l summary (fused): 464 layers, 25,282,396 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 400/400 [00:31<00:00, 12.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.826      0.791       0.85      0.679\n",
      "          easy_visible       6911       6911       0.97      0.986      0.992      0.871\n",
      "      visible_not_easy        626        626      0.729      0.736      0.805      0.638\n",
      "                hidden         43         43      0.778      0.651      0.752      0.528\n",
      "Speed: 0.1ms preprocess, 1.4ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = CustomTrackingModel(\n",
    "    batch_size=70,\n",
    "    stack_size=4,\n",
    "    model_path=Path(\"\"),\n",
    "    data_path=Path(\"dataset\"),\n",
    "    output_path=Path(\"output\")\n",
    ")\n",
    "\n",
    "# Обучение модели (предполагается, что data.yaml настроен)\n",
    "model.train_model(data_config=Path(\"dataset.yaml\"), epochs=50, imgsz=640, load_existing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка модели YOLOv11...\n",
      "Loading model from https://drive.google.com/uc?id=1Wegd5CSWgk6iKoyDNmex6gNwhUmkhSQI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1Wegd5CSWgk6iKoyDNmex6gNwhUmkhSQI\n",
      "From (redirected): https://drive.google.com/uc?id=1Wegd5CSWgk6iKoyDNmex6gNwhUmkhSQI&confirm=t&uuid=27305e22-5d13-4032-8ed9-58408fec1807\n",
      "To: /opt/notebooks/sports-tracking-tystem/best.pt\n",
      "100%|██████████| 51.2M/51.2M [00:00<00:00, 105MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from best.pt\n",
      "Модель YOLOv11 успешно загружена.\n"
     ]
    }
   ],
   "source": [
    "#  Пример использования:\n",
    "model = CustomTrackingModel(\n",
    "    batch_size=32,\n",
    "    stack_size=4,\n",
    "    model_path=Path(\"runs/detect/train10/weights/best.pt\"),\n",
    "    data_path=Path(\"dataset\"),\n",
    "    output_path=Path(\"output\")\n",
    ")\n",
    "\n",
    "model.load()  # Загружаем модель\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 3795 изображений и 3795 аннотаций.\n",
      "Найдено 3795 общих пар изображений и аннотаций.\n",
      "Копирование 3795 изображений и аннотаций в обучающую выборку.\n",
      "Копирование 0 изображений и аннотаций в валидационную выборку.\n",
      "Разделение данных завершено.\n",
      "Среднее значение SIBATRACC: 0.8580679450223773\n"
     ]
    }
   ],
   "source": [
    "\n",
    "average_sibatracc = model.test(data_path=Path(\"tennis\"), games=[1, 2], do_visualization=False, test_name='test', yolo_format=False)\n",
    "print(f\"Среднее значение SIBATRACC: {average_sibatracc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_from_images_with_tracking(model, image_files: list, clip_name: str, output_path: Path, fps: int = 30):\n",
    "    if not image_files:\n",
    "        print(f\"No images found for {clip_name}.\")\n",
    "        return\n",
    "    print(f\"Found {len(image_files)} images for {clip_name}. Creating tracked video...\")\n",
    "\n",
    "    temp_dir = Path(\"temp_tracking_dir\")\n",
    "    if temp_dir.exists():\n",
    "        shutil.rmtree(temp_dir)\n",
    "    temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for img_file in image_files:\n",
    "        shutil.copy(img_file, temp_dir / img_file.name)\n",
    "\n",
    "    results = model.predict_with_tracking(clip_name=clip_name, image_dir=temp_dir)\n",
    "\n",
    "    first_frame = cv2.imread(str(image_files[0]))\n",
    "    if first_frame is None:\n",
    "        print(\"Unable to read the first frame. Check your images.\")\n",
    "        shutil.rmtree(temp_dir)\n",
    "        return\n",
    "\n",
    "    height, width, _ = first_frame.shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))\n",
    "\n",
    "    for i, frame_results in enumerate(results):\n",
    "        frame = cv2.imread(str(image_files[i]))\n",
    "        if frame is None:\n",
    "            print(f\"Unable to read frame {image_files[i]}. Skipping...\")\n",
    "            continue\n",
    "        for box in frame_results:\n",
    "            x1, y1, x2, y2 = int(box['x1']), int(box['y1']), int(box['x2']), int(box['y2'])\n",
    "            track_id = box['track_id']\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"ID: {track_id}\", (x1, max(0, y1 - 5)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        video.write(frame)\n",
    "\n",
    "    video.release()\n",
    "    print(f\"Video with tracking saved to {output_path}.\")\n",
    "    shutil.rmtree(temp_dir)\n",
    "\n",
    "\n",
    "def create_video_for_game_clip(model, game_number: int, clip_number: int, data_path: Path, output_path: Path, fps: int = 30):\n",
    "    images_dir = data_path / \"images\" / \"test\"\n",
    "    clip_name = f\"game{game_number}_clip{clip_number}\"\n",
    "    image_files = sorted(images_dir.glob(f\"{clip_name}_*.jpg\"))\n",
    "\n",
    "    output_file = output_path / f\"{clip_name}_tracked.mp4\"\n",
    "    create_video_from_images_with_tracking(model, image_files, clip_name, output_file, fps)\n",
    "\n",
    "\n",
    "def create_video_for_game(model, game_number: int, data_path: Path, output_path: Path, fps: int = 30):\n",
    "    images_dir = data_path / \"images\" / \"test\"\n",
    "    game_prefix = f\"game{game_number}_clip\"\n",
    "    image_files = sorted(images_dir.glob(f\"{game_prefix}*.jpg\"))\n",
    "\n",
    "    clip_name = f\"game{game_number}_full\"\n",
    "    output_file = output_path / f\"{clip_name}_tracked.mp4\"\n",
    "    create_video_from_images_with_tracking(model, image_files, clip_name, output_file, fps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка модели YOLOv8...\n",
      "Модель YOLOv8 успешно загружена.\n",
      "Found 359 images for game2_clip3. Creating tracked video...\n",
      "Video with tracking saved to output/game2_clip3_tracked.mp4.\n",
      "Found 1573 images for game2_full. Creating tracked video...\n",
      "\n",
      "WARNING ⚠️ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "Video with tracking saved to output/game2_full_tracked.mp4.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = CustomTrackingModel(\n",
    "    batch_size=32,\n",
    "    stack_size=4,\n",
    "    model_path=Path(\"runs/detect/train10/weights/best.pt\"),\n",
    "    data_path=Path(\"dataset\"),\n",
    "    output_path=Path(\"output\")\n",
    ")\n",
    "model.load()\n",
    "\n",
    "create_video_for_game_clip(model, game_number=2, clip_number=3, data_path=Path(\"dataset\"), output_path=Path(\"output\"), fps=30)\n",
    "\n",
    "create_video_for_game(model, game_number=2, data_path=Path(\"dataset\"), output_path=Path(\"output\"), fps=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
