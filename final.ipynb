{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import gc\n",
    "from typing import List, Tuple, Optional\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO  \n",
    "import torch\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_data(images_dir, labels_dir, train_images_dir, train_labels_dir, val_images_dir, val_labels_dir, split_ratio=0.8):\n",
    "    \"\"\"\n",
    "    –†–∞–∑–¥–µ–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏.\n",
    "    \n",
    "    Args:\n",
    "        images_dir (Path): –ü—É—Ç—å –∫ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ (processed_images/train/).\n",
    "        labels_dir (Path): –ü—É—Ç—å –∫ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏ YOLO (processed_labels/train/).\n",
    "        train_images_dir (Path): –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –æ–±—É—á–∞—é—â–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.\n",
    "        train_labels_dir (Path): –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –æ–±—É—á–∞—é—â–∏—Ö –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π.\n",
    "        val_images_dir (Path): –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.\n",
    "        val_labels_dir (Path): –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π.\n",
    "        split_ratio (float, optional): –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.\n",
    "    \"\"\"\n",
    "    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏\n",
    "    image_files = list(images_dir.glob('*.jpg'))\n",
    "    label_files = list(labels_dir.glob('*.txt'))\n",
    "    \n",
    "    print(f\"–ù–∞–π–¥–µ–Ω–æ {len(image_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ {len(label_files)} –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π.\")\n",
    "    \n",
    "    # –°–æ–∑–¥–∞—ë–º —Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞\n",
    "    image_dict = {img.stem: img for img in image_files}\n",
    "    label_dict = {lbl.stem: lbl for lbl in label_files}\n",
    "    \n",
    "    # –ù–∞—Ö–æ–∂–¥–µ–Ω–∏–µ –æ–±—â–∏—Ö –∫–ª—é—á–µ–π (–∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π)\n",
    "    common_keys = set(image_dict.keys()).intersection(set(label_dict.keys()))\n",
    "    \n",
    "    print(f\"–ù–∞–π–¥–µ–Ω–æ {len(common_keys)} –æ–±—â–∏—Ö –ø–∞—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π.\")\n",
    "    \n",
    "    if len(common_keys) == 0:\n",
    "        print(\"–ù–µ—Ç –æ–±—â–∏—Ö –ø–∞—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π.\")\n",
    "        return\n",
    "    \n",
    "    # –°–æ–∑–¥–∞—ë–º —Å–ø–∏—Å–∫–∏ –æ–±—â–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π\n",
    "    common_images = [image_dict[k] for k in common_keys]\n",
    "    common_labels = [label_dict[k] for k in common_keys]\n",
    "    \n",
    "    # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "    combined = list(zip(common_images, common_labels))\n",
    "    random.shuffle(combined)\n",
    "    common_images[:], common_labels[:] = zip(*combined)\n",
    "    \n",
    "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–Ω–¥–µ–∫—Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è\n",
    "    split_idx = int(len(common_images) * split_ratio)\n",
    "    train_images = common_images[:split_idx]\n",
    "    train_labels = common_labels[:split_idx]\n",
    "    val_images = common_images[split_idx:]\n",
    "    val_labels = common_labels[split_idx:]\n",
    "    \n",
    "    print(f\"–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ {len(train_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –≤ –æ–±—É—á–∞—é—â—É—é –≤—ã–±–æ—Ä–∫—É.\")\n",
    "    print(f\"–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ {len(val_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –≤ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É.\")\n",
    "    \n",
    "    # –ö–æ–ø–∏—Ä—É–µ–º –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ\n",
    "    for img, lbl in zip(train_images, train_labels):\n",
    "        shutil.copy(img, train_images_dir / img.name)\n",
    "        shutil.copy(lbl, train_labels_dir / lbl.name)\n",
    "    \n",
    "    # –ö–æ–ø–∏—Ä—É–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "    for img, lbl in zip(val_images, val_labels):\n",
    "        shutil.copy(img, val_images_dir / img.name)\n",
    "        shutil.copy(lbl, val_labels_dir / lbl.name)\n",
    "    \n",
    "    print(\"–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Metrics:\n",
    "    @staticmethod\n",
    "    def position_error(label_gt: np.ndarray, label_pr: np.ndarray, step=8, alpha=1.5, e1=5, e2=5) -> float:\n",
    "        # –ö–æ–¥—ã gt:\n",
    "        # 0 - –º—è—á –Ω–µ –≤ –∫–∞–¥—Ä–µ\n",
    "        # 1 - –º—è—á –ª–µ–≥–∫–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ–º\n",
    "        # 2 - –º—è—á –≤ –∫–∞–¥—Ä–µ, –Ω–æ –Ω–µ –ª–µ–≥–∫–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ–º\n",
    "        # 3 - –º—è—á —Å–∫—Ä—ã—Ç\n",
    "        if label_gt[0] != 0 and label_pr[0] == 0:\n",
    "            return e1\n",
    "        if label_gt[0] == 0 and label_pr[0] != 0:\n",
    "            return e2\n",
    "        dist = math.sqrt((label_gt[1] - label_pr[1]) ** 2 + (label_gt[2] - label_pr[2]) ** 2)\n",
    "        pe = math.floor(dist / step) ** alpha\n",
    "        pe = min(pe, 5)\n",
    "        return pe\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate_predictions(labels_gt: np.ndarray, labels_pr: np.ndarray) -> Tuple[List[float], float]:\n",
    "        pe = [Metrics.position_error(labels_gt[i], labels_pr[i]) for i in range(len(labels_gt))]\n",
    "        SIBATRACC_vals = []\n",
    "        for i in range(len(pe)):\n",
    "            cumulative_pe = sum(pe[:i + 1])\n",
    "            SIBATRACC_vals.append(1 - cumulative_pe / ((i + 1) * 5))\n",
    "        SIBATRACC_total = 1 - sum(pe) / (len(labels_gt) * 5) if len(labels_gt) > 0 else 0\n",
    "        return SIBATRACC_vals, SIBATRACC_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "import gdown\n",
    "\n",
    "def get_game_clip_pairs(data_path: Path, games: List[int]) -> List[tuple]:\n",
    "    image_dir = data_path / \"images\" / \"test\"\n",
    "    clip_names = set()\n",
    "    for image_file in image_dir.glob(\"*.jpg\"):\n",
    "        parts = image_file.name.split('_')\n",
    "        clip_name = '_'.join(parts[:-1])\n",
    "        clip_names.add(clip_name)\n",
    "\n",
    "    game_clip_pairs = []\n",
    "    for clip_name in sorted(clip_names):\n",
    "        g_part = clip_name.split('_')[0]  \n",
    "        g_num = int(g_part.replace('game', ''))\n",
    "        if g_num in games:\n",
    "            game_clip_pairs.append((g_num, clip_name))\n",
    "            \n",
    "    return game_clip_pairs\n",
    "\n",
    "\n",
    "class CustomTrackingModel:\n",
    "    def __init__(self, batch_size: int, stack_size: int, model_path: Path, data_path: Path, output_path: Path):\n",
    "        self.batch_size = batch_size\n",
    "        self.stack_size = stack_size\n",
    "        self.model_path = model_path\n",
    "        self.data_path = data_path\n",
    "        self.output_path = output_path\n",
    "        self.model = None  # –ë—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –≤ –º–µ—Ç–æ–¥–µ load()\n",
    "\n",
    "    def load(self, path=\"best.pt\", load_from_cloud=True):\n",
    "        # LBL5\n",
    "        print(\"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ YOLOv11...\")\n",
    "        if load_from_cloud:\n",
    "            url = f\"https://drive.google.com/uc?id=1Wegd5CSWgk6iKoyDNmex6gNwhUmkhSQI\"\n",
    "            print(f\"Loading model from {url}\")\n",
    "            gdown.download(url, path, quiet=False)\n",
    "            print(f\"Loading model from {path}\")\n",
    "            self.model = YOLO(str(path), task='detect')\n",
    "\n",
    "        else:\n",
    "            self.model = YOLO(str(self.model_path))\n",
    "        print(\"–ú–æ–¥–µ–ª—å YOLOv11 —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.\")\n",
    "\n",
    "    def load_images(self, clip_name: str) -> np.ndarray:\n",
    "        image_dir = self.data_path / \"images\" / \"test\"\n",
    "        images = []\n",
    "        for image_file in sorted(image_dir.glob(f\"{clip_name}*.jpg\")):\n",
    "            img = Image.open(image_file).convert(\"RGB\")\n",
    "            images.append(np.array(img))\n",
    "        return np.array(images)\n",
    "\n",
    "    def load_labels(self, clip_name: str) -> np.ndarray:\n",
    "        label_dir = self.data_path / \"labels\" / \"test\"\n",
    "        labels = []\n",
    "        image_width = 1280\n",
    "        image_height = 720\n",
    "\n",
    "        for label_file in sorted(label_dir.glob(f\"{clip_name}*.txt\")):\n",
    "            with open(label_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                if len(lines) == 0:\n",
    "                    labels.append([0.0, 0.0, 0.0])\n",
    "                else:\n",
    "                    class_id, x_center, y_center, width, height = map(float, lines[0].split())\n",
    "                    x_center_abs = x_center * image_width\n",
    "                    y_center_abs = y_center * image_height\n",
    "                    labels.append([class_id, x_center_abs, y_center_abs])\n",
    "        \n",
    "        return np.array(labels)\n",
    "    \n",
    "    def convert_labels_to_yolo(self, game, clip, image_dir, label_csv, output_images_dir, output_labels_dir, image_width=1280, image_height=720):\n",
    "        #LBL4\n",
    "        \"\"\"\n",
    "        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –∏–∑ labels.csv –≤ —Ñ–æ—Ä–º–∞—Ç YOLO —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏ —Ñ–∞–π–ª–æ–≤.\n",
    "        –ö–æ–ø–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –µ–¥–∏–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏.\n",
    "        –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –≤—Å–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –æ–¥–∏–Ω .txt —Ñ–∞–π–ª.\n",
    "        \n",
    "        Args:\n",
    "            game (str): –ù–∞–∑–≤–∞–Ω–∏–µ –∏–≥—Ä—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'game1').\n",
    "            clip (str): –ù–∞–∑–≤–∞–Ω–∏–µ –∫–ª–∏–ø–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'clip1').\n",
    "            image_dir (Path): –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.\n",
    "            label_csv (Path): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É labels.csv.\n",
    "            output_images_dir (Path): –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏.\n",
    "            output_labels_dir (Path): –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è YOLO-–∞–Ω–Ω–æ—Ç–∞—Ü–∏–π.\n",
    "            image_width (int): –®–∏—Ä–∏–Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.\n",
    "            image_height (int): –í—ã—Å–æ—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.\n",
    "        \"\"\"\n",
    "        output_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        output_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        if not label_csv.exists():\n",
    "            print(f\"–§–∞–π–ª {label_csv} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–ø—É—Å–∫...\")\n",
    "            return\n",
    "        \n",
    "        df = pd.read_csv(label_csv)\n",
    "        \n",
    "        grouped = df.groupby('file name')\n",
    "        \n",
    "        for filename, group in grouped:\n",
    "            visibility = group['visibility'].iloc[0] \n",
    "            if visibility == 0:\n",
    "\n",
    "                unique_stem = f\"{game}_{clip}_{Path(filename).stem}\"\n",
    "                label_path = output_labels_dir / f\"{unique_stem}.txt\"\n",
    "                label_path.touch(exist_ok=True)\n",
    "                \n",
    "                image_path = image_dir / filename\n",
    "                unique_image_name = f\"{unique_stem}.jpg\"\n",
    "                new_image_path = output_images_dir / unique_image_name\n",
    "                if not new_image_path.exists():\n",
    "                    shutil.copy(image_path, new_image_path)\n",
    "                continue\n",
    "            \n",
    "            yolo_annotations = []\n",
    "            \n",
    "            for _, row in group.iterrows():\n",
    "                x = row['x-coordinate']\n",
    "                y = row['y-coordinate']\n",
    "                status = row['status']\n",
    "                visibility = row['visibility']\n",
    "\n",
    "                if pd.isna(x) or pd.isna(y):\n",
    "                    continue\n",
    "\n",
    "                x_center = float(x) / image_width\n",
    "                y_center = float(y) / image_height\n",
    "\n",
    "                width = 0.05\n",
    "                height = 0.05\n",
    "\n",
    "                \n",
    "                class_id = int(visibility)\n",
    "\n",
    "                yolo_annotation = f\"{class_id} {x_center} {y_center} {width} {height}\"\n",
    "                yolo_annotations.append(yolo_annotation)\n",
    "            \n",
    "            if not yolo_annotations:\n",
    "                unique_stem = f\"{game}_{clip}_{Path(filename).stem}\"\n",
    "                label_path = output_labels_dir / f\"{unique_stem}.txt\"\n",
    "                label_path.touch(exist_ok=True)\n",
    "            else:\n",
    "                unique_stem = f\"{game}_{clip}_{Path(filename).stem}\"\n",
    "                \n",
    "                label_path = output_labels_dir / f\"{unique_stem}.txt\"\n",
    "                with open(label_path, 'w') as f:\n",
    "                    f.write('\\n'.join(yolo_annotations) + '\\n')\n",
    "            \n",
    "            image_path = image_dir / filename\n",
    "            unique_image_name = f\"{unique_stem}.jpg\"\n",
    "            new_image_path = output_images_dir / unique_image_name\n",
    "            if not new_image_path.exists():\n",
    "                shutil.copy(image_path, new_image_path)\n",
    "\n",
    "    def predict_on_batch(self, batch: np.ndarray) -> List[dict]:\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –í—ã–∑–æ–≤–∏—Ç–µ –º–µ—Ç–æ–¥ load() –ø–µ—Ä–µ–¥ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º.\")\n",
    "        image_list = [Image.fromarray(img) for img in batch.astype(np.uint8)]\n",
    "        results = self.model(image_list, verbose=False)\n",
    "        return results\n",
    "\n",
    "    def get_labels_from_prediction(self, predictions: List[Optional[dict]], upscale_coords: bool, original_size: Tuple[int, int]) -> np.ndarray:\n",
    "        coords = np.zeros((len(predictions), 7), dtype=np.float32) \n",
    "        original_width, original_height = original_size\n",
    "        \n",
    "        for i, frame_preds in enumerate(predictions):\n",
    "            if frame_preds is None or not frame_preds.boxes:\n",
    "                coords[i] = [0, 0, 0, 0, 0, 0, 0]\n",
    "                continue\n",
    "            ball_pred = max(frame_preds.boxes, key=lambda box: box.conf)\n",
    "            class_id = int(ball_pred.cls)\n",
    "            x1 = float(ball_pred.xyxy[0][0])\n",
    "            y1 = float(ball_pred.xyxy[0][1])\n",
    "            x2 = float(ball_pred.xyxy[0][2])\n",
    "            y2 = float(ball_pred.xyxy[0][3])\n",
    "            x_center = (x1 + x2) / 2\n",
    "            y_center = (y1 + y2) / 2\n",
    "            if upscale_coords:\n",
    "                scale_x = original_width / frame_preds.orig_shape[1]\n",
    "                scale_y = original_height / frame_preds.orig_shape[0]\n",
    "                x_center *= scale_x\n",
    "                y_center *= scale_y\n",
    "                x1 *= scale_x\n",
    "                y1 *= scale_y\n",
    "                x2 *= scale_x\n",
    "                y2 *= scale_y\n",
    "            coords[i] = [class_id, x_center, y_center, x1, y1, x2, y2]\n",
    "        \n",
    "        return coords\n",
    "\n",
    "    def evaluate_predictions(self, ground_truth: np.ndarray, predictions: np.ndarray) -> float:\n",
    "        SIBATRACC_per_frame, SIBATRACC_total = Metrics.evaluate_predictions(ground_truth, predictions)\n",
    "        return SIBATRACC_total\n",
    "\n",
    "    def test(self, data_path: Path, games: List[int], do_visualization=False, test_name='test', yolo_format=False) -> float:\n",
    "        if not yolo_format:\n",
    "            test_games = games\n",
    "            test_dir = data_path / test_name\n",
    "\n",
    "            output_images_dir = Path('processed_images/test/')\n",
    "            output_labels_dir = Path('processed_labels/test/')\n",
    "\n",
    "            for game in test_games:\n",
    "                game_dir = test_dir / f'game{game}'\n",
    "                if not game_dir.exists():\n",
    "                    print(f\"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {game_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü—Ä–æ–ø—É—Å–∫...\")\n",
    "                    continue\n",
    "                for clip in game_dir.iterdir():\n",
    "                    if clip.is_dir():\n",
    "                        image_dir = clip\n",
    "                        label_csv = clip / 'labels.csv'\n",
    "                        if label_csv.exists():\n",
    "                            self.convert_labels_to_yolo(\n",
    "                                game=f'game{game}',\n",
    "                                clip=clip.name,\n",
    "                                image_dir=image_dir,\n",
    "                                label_csv=label_csv,\n",
    "                                output_images_dir=output_images_dir,\n",
    "                                output_labels_dir=output_labels_dir,\n",
    "                                image_width=1280,\n",
    "                                image_height=720\n",
    "                            )\n",
    "                        else:\n",
    "                            print(f\"–§–∞–π–ª {label_csv} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ {clip}. –ü—Ä–æ–ø—É—Å–∫...\")\n",
    "\n",
    "            test_images_dir = Path('dataset/images/test/')\n",
    "            test_labels_dir = Path('dataset/labels/test/')\n",
    "            test_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "            test_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            split_data(\n",
    "                images_dir=output_images_dir,\n",
    "                labels_dir=output_labels_dir,\n",
    "                train_images_dir=test_images_dir,\n",
    "                train_labels_dir=test_labels_dir,\n",
    "                val_images_dir=None,\n",
    "                val_labels_dir=None,\n",
    "                split_ratio=1.0\n",
    "            )\n",
    "\n",
    "            \n",
    "        game_clip_pairs = get_game_clip_pairs(self.data_path, games)\n",
    "        SIBATRACC_vals = []\n",
    "        for game, clip_name in game_clip_pairs:\n",
    "            data = self.load_images(clip_name)\n",
    "            labels_gt = self.load_labels(clip_name)\n",
    "\n",
    "            predictions = self.predict_on_batch(data)\n",
    "            predicted_labels = self.get_labels_from_prediction(predictions, upscale_coords=True, original_size=(1280, 720))\n",
    "\n",
    "            SIBATRACC_per_frame, SIBATRACC_total = Metrics.evaluate_predictions(labels_gt, predicted_labels)\n",
    "            SIBATRACC_vals.append(SIBATRACC_total)\n",
    "\n",
    "            if do_visualization:\n",
    "                self.visualize_predictions(data, predicted_labels, clip_name)\n",
    "\n",
    "            del data, labels_gt, predicted_labels, predictions\n",
    "            gc.collect()\n",
    "\n",
    "        SIBATRACC_final = sum(SIBATRACC_vals) / len(SIBATRACC_vals) if SIBATRACC_vals else 0\n",
    "        return SIBATRACC_final\n",
    "\n",
    "    def visualize_predictions(self, images: np.ndarray, predicted_labels: np.ndarray, clip_name: str):\n",
    "        visualize_path = self.output_path / \"visualizations\"\n",
    "        visualize_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for i, img in enumerate(images):\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            \n",
    "            class_id, x_center, y_center, x1, y1, x2, y2 = predicted_labels[i]\n",
    "\n",
    "            if class_id != 0:\n",
    "                rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor='red', linewidth=2)\n",
    "                plt.gca().add_patch(rect)\n",
    "                plt.scatter(x_center, y_center, c='blue', s=20, marker='x')\n",
    "                plt.text(x1, y1 - 5, f'Class: {class_id}', color='yellow', fontsize=12, backgroundcolor='black')\n",
    "            \n",
    "            plt.title(f'{clip_name} Frame {i}')\n",
    "            save_path = visualize_path / f\"{clip_name}_frame_{i}.jpg\"\n",
    "            plt.savefig(save_path, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "    def train_model(self, data_config: Path, epochs: int = 50, imgsz: int = 640, load_existing: bool = True, yolo_format: bool = False):\n",
    "        # LBL1, LBL2, LBL3, LBL6, LBL13, LBL7\n",
    "        if not yolo_format:\n",
    "            train_games = [1, 2, 3, 4, 5, 6]  # –°–ø–∏—Å–æ–∫ –∏–≥—Ä –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "            train_dir = Path('tennis/train/')  # –ü—É—Ç—å –∫ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–º –¥–∞–Ω–Ω—ã–º\n",
    "            yolo_labels_dir = Path('yolo_labels/train/')  # –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è YOLO-–∞–Ω–Ω–æ—Ç–∞—Ü–∏–π\n",
    "\n",
    "            # –ü—É—Ç—å –∫ —Ü–µ–ª–µ–≤—ã–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏\n",
    "            output_images_dir = Path('processed_images/train/')\n",
    "            output_labels_dir = Path('processed_labels/train/')\n",
    "\n",
    "            for game in train_games:\n",
    "                game_dir = train_dir / f'game{game}'\n",
    "                if not game_dir.exists():\n",
    "                    print(f\"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {game_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü—Ä–æ–ø—É—Å–∫...\")\n",
    "                    continue\n",
    "                for clip in game_dir.iterdir():\n",
    "                    if clip.is_dir():\n",
    "                        image_dir = clip\n",
    "                        label_csv = clip / 'labels.csv'\n",
    "                        if label_csv.exists():\n",
    "                            self.convert_labels_to_yolo(\n",
    "                                game=f'game{game}',\n",
    "                                clip=clip.name,\n",
    "                                image_dir=image_dir,\n",
    "                                label_csv=label_csv,\n",
    "                                output_images_dir=output_images_dir,\n",
    "                                output_labels_dir=output_labels_dir,\n",
    "                                image_width=1280,\n",
    "                                image_height=720\n",
    "                            )\n",
    "                        else:\n",
    "                            print(f\"–§–∞–π–ª {label_csv} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ {clip}. –ü—Ä–æ–ø—É—Å–∫...\")\n",
    "            train_images_dir = Path('dataset/images/train/')\n",
    "            train_labels_dir = Path('dataset/labels/train/')\n",
    "            val_images_dir = Path('dataset/images/val/')\n",
    "            val_labels_dir = Path('dataset/labels/val/')\n",
    "\n",
    "            train_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "            train_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "            val_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "            val_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            processed_images_dir = Path('processed_images/train/')\n",
    "            processed_labels_dir = Path('processed_labels/train/')\n",
    "\n",
    "            split_data(\n",
    "                images_dir=processed_images_dir,\n",
    "                labels_dir=processed_labels_dir,\n",
    "                train_images_dir=train_images_dir,\n",
    "                train_labels_dir=train_labels_dir,\n",
    "                val_images_dir=val_images_dir,\n",
    "                val_labels_dir=val_labels_dir,\n",
    "                split_ratio=0.8\n",
    "            )\n",
    "        if self.model is None:\n",
    "            if self.model_path.exists() and load_existing:\n",
    "                self.model = YOLO(str(self.model_path))\n",
    "            else:\n",
    "                self.model = YOLO('yolo11l.pt')  \n",
    "\n",
    "        self.model.train(\n",
    "            data=str(data_config),\n",
    "            epochs=epochs,\n",
    "            batch=self.batch_size,\n",
    "            imgsz=imgsz,\n",
    "            workers=32,\n",
    "            device='0'\n",
    "        )\n",
    "\n",
    "    def predict_with_tracking(self, clip_name: str, image_dir: Path) -> List[dict]:\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –í—ã–∑–æ–≤–∏—Ç–µ –º–µ—Ç–æ–¥ load() –ø–µ—Ä–µ–¥ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º.\")\n",
    "\n",
    "        results = self.model.track(source=str(image_dir), conf=0.5, save=False, verbose=False, iou=0.5)\n",
    "        all_predictions = []\n",
    "        for res in results:\n",
    "            frame_data = []\n",
    "            for box in res.boxes:\n",
    "                cls = int(box.cls)\n",
    "                conf = float(box.conf)\n",
    "                x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "                track_id = int(box.id) if box.id is not None else -1\n",
    "                x_center = (x1 + x2) / 2.0\n",
    "                y_center = (y1 + y2) / 2.0\n",
    "                frame_data.append({\n",
    "                    'class_id': cls,\n",
    "                    'conf': conf,\n",
    "                    'track_id': track_id,\n",
    "                    'x_center': x_center,\n",
    "                    'y_center': y_center,\n",
    "                    'x1': x1,\n",
    "                    'y1': y1,\n",
    "                    'x2': x2,\n",
    "                    'y2': y2\n",
    "                })\n",
    "            all_predictions.append(frame_data)\n",
    "\n",
    "        return all_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.51 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.47 üöÄ Python-3.11.5 torch-2.5.1+cu124 CUDA:0 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:1 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:3 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:4 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:5 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:6 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:7 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11l.pt, data=dataset.yaml, epochs=50, time=None, patience=100, batch=70, imgsz=640, save=True, save_period=-1, cache=False, device=[0, 1, 3, 4, 5, 6, 7], workers=32, project=None, name=train10, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734640904.815290 3999282 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734640904.820624 3999282 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 23        [16, 19, 22]  1   1414108  ultralytics.nn.modules.head.Detect           [4, [256, 512, 512]]          \n",
      "YOLO11l summary: 631 layers, 25,313,564 parameters, 25,313,548 gradients, 87.3 GFLOPs\n",
      "\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/notebooks/sports-tracking-tystem/.venv/bin/python -m torch.distributed.run --nproc_per_node 7 --master_port 55979 /root/.config/Ultralytics/DDP/_temp_ynql0j5c140609300772880.py\n",
      "Ultralytics 8.3.47 üöÄ Python-3.11.5 torch-2.5.1+cu124 CUDA:0 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:1 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:3 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:4 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:5 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:6 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:7 (NVIDIA A100-SXM4-80GB, 81158MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734640914.896321 3999908 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734640914.901641 3999908 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train10', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /opt/notebooks/sports-tracking-tystem/dataset/labels/train... 11903 images, 599 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11903/11903 [00:08<00:00, 1330.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /opt/notebooks/sports-tracking-tystem/dataset/labels/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /opt/notebooks/sports-tracking-tystem/dataset/labels/val... 7982 images, 402 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7982/7982 [00:05<00:00, 1495.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /opt/notebooks/sports-tracking-tystem/dataset/labels/val.cache\n",
      "Plotting labels to runs/detect/train10/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.000546875), 173 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 126 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train10\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      7.27G      1.903      3.521      1.155          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:48<00:00,  3.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:33<00:00, 12.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.711      0.354      0.419      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      7.29G      1.294      1.147     0.9191          0        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:47<00:00,  3.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:33<00:00, 11.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.879      0.255      0.285      0.188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      7.35G      1.215      1.088     0.9017          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.706      0.343      0.362      0.224\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      7.31G      1.136     0.9801     0.8895          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.665      0.339      0.336      0.243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      7.29G      1.032     0.8959     0.8724          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.631      0.366      0.432      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      7.29G     0.9787     0.8666     0.8584          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.554      0.501      0.479      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      7.28G     0.9533     0.8461     0.8493          0        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.481      0.508      0.471      0.339\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      7.28G     0.9216     0.7951     0.8447          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.552      0.512      0.476      0.354\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      7.28G     0.9077     0.7589     0.8439          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.567       0.54      0.492      0.353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      7.28G     0.8943     0.7603     0.8407          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.565      0.529      0.512      0.376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      7.29G     0.8767     0.7146     0.8379          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.566      0.572      0.518      0.384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      7.28G     0.8663     0.7207     0.8346          0        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.568      0.558      0.529      0.403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      7.28G     0.8566      0.733     0.8368          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.597      0.557      0.564      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      7.29G     0.8621     0.7574     0.8381          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.669      0.504      0.541      0.415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      7.28G     0.8394     0.6983     0.8329          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.601      0.587      0.565      0.431\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      7.28G      0.855     0.7082     0.8342          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580       0.63      0.608      0.581      0.436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      7.28G     0.8241     0.6854     0.8309          0        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.629      0.632      0.595      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      7.28G     0.8252     0.6579     0.8328          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.624      0.618      0.601      0.457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      7.28G     0.8149     0.6152     0.8308          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.658      0.587      0.605      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      7.28G      0.803     0.6338      0.828          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.601      0.636      0.585      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      7.28G     0.7851     0.6118     0.8205          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.672      0.631      0.619      0.472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      7.28G     0.7866     0.5894     0.8243          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.683      0.625      0.633      0.483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      7.28G     0.7744     0.5533     0.8247          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.637      0.623      0.634      0.489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      7.28G     0.7607     0.5766      0.818          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.632      0.653      0.646      0.486\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      7.28G     0.7399     0.5907     0.8173          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.678      0.646      0.648      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      7.28G      0.722     0.5677     0.8141          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.675      0.669      0.659      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      7.28G     0.7415     0.5444     0.8212          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580       0.64      0.682      0.647      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      7.28G     0.7215     0.5552     0.8149          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:31<00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.713      0.675       0.69      0.538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/171 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      7.28G      0.705     0.5276     0.8117          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:31<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.653      0.755      0.695      0.541\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      7.28G     0.7083     0.5047     0.8074          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580       0.68      0.699      0.693      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      7.28G     0.7101      0.516     0.8152          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:31<00:00, 12.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.694       0.68      0.697      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      7.28G     0.7163      0.519     0.8189          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:31<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.753      0.688      0.735      0.576\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      7.28G     0.7019     0.5146     0.8127          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:31<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.705      0.741       0.73      0.579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      7.28G     0.6908        0.5     0.8145          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.682      0.763      0.743      0.584\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      7.28G     0.6897     0.4883     0.8018          0        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:47<00:00,  3.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:31<00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.726      0.782      0.776      0.602\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      7.28G     0.6877     0.4837     0.8078          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:31<00:00, 12.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.732      0.756      0.759      0.595\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      7.28G     0.6724     0.4634     0.8045          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:45<00:00,  3.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.795      0.731       0.78      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      7.28G     0.6663     0.4739     0.8095          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:32<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.787       0.74       0.78      0.613\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      7.28G     0.6695     0.4729     0.8082          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:31<00:00, 12.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.749      0.758      0.791      0.619\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      7.28G     0.6557     0.4586     0.8107          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:31<00:00, 12.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.747      0.765      0.793      0.621\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      7.28G      0.628     0.4141     0.8037          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:47<00:00,  3.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:31<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.714      0.758      0.772      0.612\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      7.28G     0.6236     0.4003     0.8073          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:31<00:00, 12.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.783      0.718      0.783      0.624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      7.28G     0.6257     0.4192     0.8133          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:47<00:00,  3.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:31<00:00, 12.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.756      0.779      0.811      0.651\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      7.28G     0.6122     0.3806     0.8022          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:47<00:00,  3.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:31<00:00, 12.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.791      0.757       0.81      0.652\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      7.28G     0.6222     0.4173     0.8037          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:47<00:00,  3.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:31<00:00, 12.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.816      0.779      0.813      0.652\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      7.28G     0.5984     0.3905     0.8007          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:47<00:00,  3.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:31<00:00, 12.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.819      0.782       0.82      0.658\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      7.28G     0.6078     0.3594      0.798          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:47<00:00,  3.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:31<00:00, 12.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.859      0.762      0.828      0.658\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      7.28G     0.6012     0.3477     0.8038          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:47<00:00,  3.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:31<00:00, 12.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.867      0.752      0.835      0.667\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      7.28G     0.5936     0.3474     0.8013          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:46<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:31<00:00, 12.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.834      0.768      0.843      0.678\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      7.28G     0.5944      0.347     0.8041          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:47<00:00,  3.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:31<00:00, 12.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.826      0.791       0.85      0.678\n",
      "\n",
      "50 epochs completed in 1.117 hours.\n",
      "Optimizer stripped from runs/detect/train10/weights/last.pt, 51.2MB\n",
      "Optimizer stripped from runs/detect/train10/weights/best.pt, 51.2MB\n",
      "\n",
      "Validating runs/detect/train10/weights/best.pt...\n",
      "Ultralytics 8.3.47 üöÄ Python-3.11.5 torch-2.5.1+cu124 CUDA:0 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:1 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:3 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:4 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:5 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:6 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:7 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "YOLO11l summary (fused): 464 layers, 25,282,396 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:31<00:00, 12.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       7982       7580      0.826      0.791       0.85      0.679\n",
      "          easy_visible       6911       6911       0.97      0.986      0.992      0.871\n",
      "      visible_not_easy        626        626      0.729      0.736      0.805      0.638\n",
      "                hidden         43         43      0.778      0.651      0.752      0.528\n",
      "Speed: 0.1ms preprocess, 1.4ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = CustomTrackingModel(\n",
    "    batch_size=70,\n",
    "    stack_size=4,\n",
    "    model_path=Path(\"\"),\n",
    "    data_path=Path(\"dataset\"),\n",
    "    output_path=Path(\"output\")\n",
    ")\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ data.yaml –Ω–∞—Å—Ç—Ä–æ–µ–Ω)\n",
    "model.train_model(data_config=Path(\"dataset.yaml\"), epochs=50, imgsz=640, load_existing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ YOLOv11...\n",
      "Loading model from https://drive.google.com/uc?id=1Wegd5CSWgk6iKoyDNmex6gNwhUmkhSQI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1Wegd5CSWgk6iKoyDNmex6gNwhUmkhSQI\n",
      "From (redirected): https://drive.google.com/uc?id=1Wegd5CSWgk6iKoyDNmex6gNwhUmkhSQI&confirm=t&uuid=27305e22-5d13-4032-8ed9-58408fec1807\n",
      "To: /opt/notebooks/sports-tracking-tystem/best.pt\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51.2M/51.2M [00:00<00:00, 105MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from best.pt\n",
      "–ú–æ–¥–µ–ª—å YOLOv11 —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.\n"
     ]
    }
   ],
   "source": [
    "#  –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:\n",
    "model = CustomTrackingModel(\n",
    "    batch_size=32,\n",
    "    stack_size=4,\n",
    "    model_path=Path(\"runs/detect/train10/weights/best.pt\"),\n",
    "    data_path=Path(\"dataset\"),\n",
    "    output_path=Path(\"output\")\n",
    ")\n",
    "\n",
    "model.load()  # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ù–∞–π–¥–µ–Ω–æ 3795 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ 3795 –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π.\n",
      "–ù–∞–π–¥–µ–Ω–æ 3795 –æ–±—â–∏—Ö –ø–∞—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π.\n",
      "–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ 3795 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –≤ –æ–±—É—á–∞—é—â—É—é –≤—ã–±–æ—Ä–∫—É.\n",
      "–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ 0 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –≤ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É.\n",
      "–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\n",
      "–°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ SIBATRACC: 0.8580679450223773\n"
     ]
    }
   ],
   "source": [
    "\n",
    "average_sibatracc = model.test(data_path=Path(\"tennis\"), games=[1, 2], do_visualization=False, test_name='test', yolo_format=False)\n",
    "print(f\"–°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ SIBATRACC: {average_sibatracc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_from_images_with_tracking(model, image_files: list, clip_name: str, output_path: Path, fps: int = 30):\n",
    "    if not image_files:\n",
    "        print(f\"No images found for {clip_name}.\")\n",
    "        return\n",
    "    print(f\"Found {len(image_files)} images for {clip_name}. Creating tracked video...\")\n",
    "\n",
    "    temp_dir = Path(\"temp_tracking_dir\")\n",
    "    if temp_dir.exists():\n",
    "        shutil.rmtree(temp_dir)\n",
    "    temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for img_file in image_files:\n",
    "        shutil.copy(img_file, temp_dir / img_file.name)\n",
    "\n",
    "    results = model.predict_with_tracking(clip_name=clip_name, image_dir=temp_dir)\n",
    "\n",
    "    first_frame = cv2.imread(str(image_files[0]))\n",
    "    if first_frame is None:\n",
    "        print(\"Unable to read the first frame. Check your images.\")\n",
    "        shutil.rmtree(temp_dir)\n",
    "        return\n",
    "\n",
    "    height, width, _ = first_frame.shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))\n",
    "\n",
    "    for i, frame_results in enumerate(results):\n",
    "        frame = cv2.imread(str(image_files[i]))\n",
    "        if frame is None:\n",
    "            print(f\"Unable to read frame {image_files[i]}. Skipping...\")\n",
    "            continue\n",
    "        for box in frame_results:\n",
    "            x1, y1, x2, y2 = int(box['x1']), int(box['y1']), int(box['x2']), int(box['y2'])\n",
    "            track_id = box['track_id']\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"ID: {track_id}\", (x1, max(0, y1 - 5)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        video.write(frame)\n",
    "\n",
    "    video.release()\n",
    "    print(f\"Video with tracking saved to {output_path}.\")\n",
    "    shutil.rmtree(temp_dir)\n",
    "\n",
    "\n",
    "def create_video_for_game_clip(model, game_number: int, clip_number: int, data_path: Path, output_path: Path, fps: int = 30):\n",
    "    images_dir = data_path / \"images\" / \"test\"\n",
    "    clip_name = f\"game{game_number}_clip{clip_number}\"\n",
    "    image_files = sorted(images_dir.glob(f\"{clip_name}_*.jpg\"))\n",
    "\n",
    "    output_file = output_path / f\"{clip_name}_tracked.mp4\"\n",
    "    create_video_from_images_with_tracking(model, image_files, clip_name, output_file, fps)\n",
    "\n",
    "\n",
    "def create_video_for_game(model, game_number: int, data_path: Path, output_path: Path, fps: int = 30):\n",
    "    images_dir = data_path / \"images\" / \"test\"\n",
    "    game_prefix = f\"game{game_number}_clip\"\n",
    "    image_files = sorted(images_dir.glob(f\"{game_prefix}*.jpg\"))\n",
    "\n",
    "    clip_name = f\"game{game_number}_full\"\n",
    "    output_file = output_path / f\"{clip_name}_tracked.mp4\"\n",
    "    create_video_from_images_with_tracking(model, image_files, clip_name, output_file, fps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ YOLOv8...\n",
      "–ú–æ–¥–µ–ª—å YOLOv8 —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.\n",
      "Found 359 images for game2_clip3. Creating tracked video...\n",
      "Video with tracking saved to output/game2_clip3_tracked.mp4.\n",
      "Found 1573 images for game2_full. Creating tracked video...\n",
      "\n",
      "WARNING ‚ö†Ô∏è inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "Video with tracking saved to output/game2_full_tracked.mp4.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = CustomTrackingModel(\n",
    "    batch_size=32,\n",
    "    stack_size=4,\n",
    "    model_path=Path(\"runs/detect/train10/weights/best.pt\"),\n",
    "    data_path=Path(\"dataset\"),\n",
    "    output_path=Path(\"output\")\n",
    ")\n",
    "model.load()\n",
    "\n",
    "create_video_for_game_clip(model, game_number=2, clip_number=3, data_path=Path(\"dataset\"), output_path=Path(\"output\"), fps=30)\n",
    "\n",
    "create_video_for_game(model, game_number=2, data_path=Path(\"dataset\"), output_path=Path(\"output\"), fps=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
